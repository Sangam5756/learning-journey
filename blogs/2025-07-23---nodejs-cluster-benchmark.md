---
date: 2025-07-23
topics: [nodejs, performance, clustering, event-loop, backend]
day: 7
---

# ğŸ“˜ Day 7 â€“ Node.js Cluster & Performance Benchmarking

## âœ… What I Worked On
- Built a benchmarking setup using **Node.js + Cluster + Worker Threads**
- Benchmarked **sync vs async route performance** using `autocannon`
- Integrated **BullMQ** for offloading heavy tasks to background workers
- Used `os.cpus()` to scale server instances across CPU cores

## ğŸ“š What I Learned

| Scenario | Requests/sec | Timeouts | Avg Latency |
|----------|--------------|----------|-------------|
| **Async Route** | âœ… ~6.2k | âœ… ~80 | âœ… ~125ms |
| **Sync Route (Blocking)** | âŒ ~240 | âŒ 3k+ | âŒ up to 10s |

- ğŸ§  **Async I/O** in Node is highly performant when you avoid blocking operations
- âš ï¸ **Sync code** kills event loop â†’ adds timeouts and high latency
- âœ… Use **cluster** module for horizontal CPU scaling
- âœ… Offload CPU-intensive work using:
  - `worker_threads`
  - Background queues (BullMQ, Redis)

## âŒ Blockers
- Initial trouble spawning isolated workers without shared memory leak
- Needed to fine-tune autocannon settings for accurate measurements

## ğŸ§  Reflection
This wasn't just coding â€” this was understanding Node.js *under the hood*. Benchmarking clarified why certain design patterns (queues, cluster, async APIs) aren't just optional â€” theyâ€™re **critical** for real-world backend performance.

## ğŸ”— References / Code
- ğŸ“‚ [Node.js Benchmarking Repo](https://github.com/Sangam5756/node-cluster-benchmark)
